{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROJEKTanalizasentymentu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCv7s6T-qR5a",
        "colab_type": "code",
        "outputId": "162837dc-eea9-48d3-8088-edd4527068f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -U tensorflow\n",
        "!pip install nltk\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 421.8MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (42.0.2)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/5f/a1a02695b96d0e09c38abf7d1576b137979cea3d060d60891622cf61276d/google_auth-1.10.1-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.10.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.10.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzkynDMJw7Ei",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn3A4Lx9qVi-",
        "colab_type": "code",
        "outputId": "418e9a59-3d9d-466f-8773-15c72e31dc3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "import string\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR1u7fMTuC2b",
        "colab_type": "code",
        "outputId": "b68e0148-0713-4881-afc9-001ce80ab062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "\n",
        "positive=pd.read_table(\"polarity.pos.csv\", encoding=\"UTF8\", header=None, names=['Review'])\n",
        "positive['Sentiment'] = 1\n",
        "positive\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the rock is destined to be the 21st century's ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>effective but too-tepid biopic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you sometimes like to go to the movies to h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>emerges as something rare , an issue movie tha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5326</th>\n",
              "      <td>both exuberantly romantic and serenely melanch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5327</th>\n",
              "      <td>mazel tov to a film about a family's joyous li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5328</th>\n",
              "      <td>standing in the shadows of motown is the best ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5329</th>\n",
              "      <td>it's nice to see piscopo again after all these...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5330</th>\n",
              "      <td>provides a porthole into that noble , tremblin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5331 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Review  Sentiment\n",
              "0     the rock is destined to be the 21st century's ...          1\n",
              "1     the gorgeously elaborate continuation of \" the...          1\n",
              "2                        effective but too-tepid biopic          1\n",
              "3     if you sometimes like to go to the movies to h...          1\n",
              "4     emerges as something rare , an issue movie tha...          1\n",
              "...                                                 ...        ...\n",
              "5326  both exuberantly romantic and serenely melanch...          1\n",
              "5327  mazel tov to a film about a family's joyous li...          1\n",
              "5328  standing in the shadows of motown is the best ...          1\n",
              "5329  it's nice to see piscopo again after all these...          1\n",
              "5330  provides a porthole into that noble , tremblin...          1\n",
              "\n",
              "[5331 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2U1WWl-VyHG",
        "colab_type": "code",
        "outputId": "ea2326a7-8a85-4d1e-846f-46220117ce92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "positive.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5331, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBzKHeFf0tmi",
        "colab_type": "code",
        "outputId": "b9b5c10d-412a-4da1-e222-7fd8595b115f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "negative=pd.read_table(\"polarity.neg.csv\", encoding=\"UTF8\", header=None, names=['Review'])\n",
        "negative[\"Sentiment\"] = 0\n",
        "negative"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>simplistic , silly and tedious.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it's so laddish and juvenile , only teenage bo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>exploitative and largely devoid of the depth o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[garbus] discards the potential for pathologic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a visually flashy but narratively opaque and e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5326</th>\n",
              "      <td>a terrible movie that some people will neverth...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5327</th>\n",
              "      <td>there are many definitions of 'time waster' bu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5328</th>\n",
              "      <td>as it stands , crocodile hunter has the hurrie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5329</th>\n",
              "      <td>the thing looks like a made-for-home-video qui...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5330</th>\n",
              "      <td>enigma is well-made , but it's just too dry an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5331 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Review  Sentiment\n",
              "0                      simplistic , silly and tedious.           0\n",
              "1     it's so laddish and juvenile , only teenage bo...          0\n",
              "2     exploitative and largely devoid of the depth o...          0\n",
              "3     [garbus] discards the potential for pathologic...          0\n",
              "4     a visually flashy but narratively opaque and e...          0\n",
              "...                                                 ...        ...\n",
              "5326  a terrible movie that some people will neverth...          0\n",
              "5327  there are many definitions of 'time waster' bu...          0\n",
              "5328  as it stands , crocodile hunter has the hurrie...          0\n",
              "5329  the thing looks like a made-for-home-video qui...          0\n",
              "5330  enigma is well-made , but it's just too dry an...          0\n",
              "\n",
              "[5331 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZiW6JTRVxAo",
        "colab_type": "code",
        "outputId": "54ead14f-3374-4af7-cd6b-ec8ed0296e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "negative.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5331, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLGDP4n42WwA",
        "colab_type": "text"
      },
      "source": [
        "## OCZYSZCZANIE DANYCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9vV5Lci1lgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_col(col):\n",
        "    col = col.strip()\n",
        "    col = col.replace(\",\",\" \")\n",
        "    col = col.replace(\"''\",\" \")\n",
        "    col = col.replace(\"'s\",\" \")\n",
        "    col = col.replace(\".\",\" \")\n",
        "    col = col.replace(\"-\",\" \")\n",
        "    col = col.replace(\"_\",\" \")\n",
        "    col = col.replace(\"[\",\" \")\n",
        "    col = col.replace(\"]\",\" \")\n",
        "    col = col.replace(\"--\",\" \")\n",
        "    col = col.replace(\"`\",\" \")\n",
        "    col = col.replace(\" '\", \" \")    \n",
        "\n",
        "    col = col.lower()\n",
        "    return col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24PuEP5B65ol",
        "colab_type": "code",
        "outputId": "798ece22-d606-42d3-d1ac-92b6659c314d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "positive['Review'] = [clean_col(c) for c in positive['Review']]\n",
        "negative['Review'] = [clean_col(c) for c in negative['Review']]\n",
        "print(positive)\n",
        "print(negative)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 Review  Sentiment\n",
            "0     the rock is destined to be the 21st century  n...          1\n",
            "1     the gorgeously elaborate continuation of \" the...          1\n",
            "2                        effective but too tepid biopic          1\n",
            "3     if you sometimes like to go to the movies to h...          1\n",
            "4     emerges as something rare   an issue movie tha...          1\n",
            "...                                                 ...        ...\n",
            "5326  both exuberantly romantic and serenely melanch...          1\n",
            "5327  mazel tov to a film about a family  joyous lif...          1\n",
            "5328  standing in the shadows of motown is the best ...          1\n",
            "5329  it  nice to see piscopo again after all these ...          1\n",
            "5330  provides a porthole into that noble   tremblin...          1\n",
            "\n",
            "[5331 rows x 2 columns]\n",
            "                                                 Review  Sentiment\n",
            "0                       simplistic   silly and tedious           0\n",
            "1     it  so laddish and juvenile   only teenage boy...          0\n",
            "2     exploitative and largely devoid of the depth o...          0\n",
            "3      garbus  discards the potential for pathologic...          0\n",
            "4     a visually flashy but narratively opaque and e...          0\n",
            "...                                                 ...        ...\n",
            "5326  a terrible movie that some people will neverth...          0\n",
            "5327  there are many definitions of time waster' but...          0\n",
            "5328  as it stands   crocodile hunter has the hurrie...          0\n",
            "5329  the thing looks like a made for home video qui...          0\n",
            "5330  enigma is well made   but it  just too dry and...          0\n",
            "\n",
            "[5331 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE6xECJt9pml",
        "colab_type": "code",
        "outputId": "2996e2d2-633c-4430-8d11-c5dec80366e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "dane=pd.concat([positive,negative],ignore_index=True)\n",
        "type(dane)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ECLjXA1Lf0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(text):\n",
        "  no_punct=\"\".join([c for c in text if c not in string.punctuation])\n",
        "  return no_punct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-0nlgnVLrYf",
        "colab_type": "code",
        "outputId": "91a1c541-911e-4c5c-f980-be500db4f21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "dane['Review']=dane['Review'].apply(lambda x: remove_punctuation(x))\n",
        "dane['Review'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    the rock is destined to be the 21st century  n...\n",
              "1    the gorgeously elaborate continuation of  the ...\n",
              "2                       effective but too tepid biopic\n",
              "3    if you sometimes like to go to the movies to h...\n",
              "4    emerges as something rare   an issue movie tha...\n",
              "Name: Review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezpTcE5b6UIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer= RegexpTokenizer(r'\\w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TUttrYOG3hW",
        "colab_type": "code",
        "outputId": "99fea420-3ba6-4c4a-9374-2dfaeb732431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "dane['Review']=dane['Review'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
        "dane['Review'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [the, rock, is, destined, to, be, the, 21st, c...\n",
              "1    [the, gorgeously, elaborate, continuation, of,...\n",
              "2                 [effective, but, too, tepid, biopic]\n",
              "3    [if, you, sometimes, like, to, go, to, the, mo...\n",
              "4    [emerges, as, something, rare, an, issue, movi...\n",
              "Name: Review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G9Sd4uPPhU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(text):\n",
        "  words=[w for w in text if w not in stopwords.words('english')]\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRb1PtXWPsDn",
        "colab_type": "code",
        "outputId": "e6f0b171-62e8-4f9a-e30f-5aef54879d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "dane['Review']=dane['Review'].apply(lambda x: remove_stopwords(x))\n",
        "dane['Review'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [rock, destined, 21st, century, new, conan, go...\n",
              "1    [gorgeously, elaborate, continuation, lord, ri...\n",
              "2                           [effective, tepid, biopic]\n",
              "3    [sometimes, like, go, movies, fun, wasabi, goo...\n",
              "4    [emerges, something, rare, issue, movie, hones...\n",
              "Name: Review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLQKOz3QOtMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "def word_lemmatizer(text):\n",
        "  lem_text=[lemmatizer.lemmatize(i) for i in text]\n",
        "  return lem_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9zdvto9O8rB",
        "colab_type": "code",
        "outputId": "9bcaca3c-1c72-401c-bd1b-84d41be4428d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "dane['Review'].apply(lambda x : word_lemmatizer(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [rock, destined, 21st, century, new, conan, go...\n",
              "1        [gorgeously, elaborate, continuation, lord, ri...\n",
              "2                               [effective, tepid, biopic]\n",
              "3        [sometimes, like, go, movie, fun, wasabi, good...\n",
              "4        [emerges, something, rare, issue, movie, hones...\n",
              "                               ...                        \n",
              "10657    [terrible, movie, people, nevertheless, find, ...\n",
              "10658    [many, definition, time, waster, movie, must, ...\n",
              "10659    [stand, crocodile, hunter, hurried, badly, cob...\n",
              "10660      [thing, look, like, made, home, video, quickie]\n",
              "10661                    [enigma, well, made, dry, placid]\n",
              "Name: Review, Length: 10662, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF9SafFKQjgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer=PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB8HjxITQ30P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_stemmer(text):\n",
        "  stem_text=\" \".join([stemmer.stem(i) for i in text])\n",
        "  return stem_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGEfWuuERAsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dane['Review']=dane['Review'].apply(lambda x: word_stemmer(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNBlnZna2cdz",
        "colab_type": "text"
      },
      "source": [
        "# MIESZANIE DANYCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OEJWLYORJ9T",
        "colab_type": "code",
        "outputId": "55750556-f578-4214-f9fe-05eb6504ca77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "dane=dane.sample(frac=1).reset_index(drop=True)\n",
        "dane"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>outer space buff might love film other find pl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serri want blend polit drama admir ambit bad h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kid often appear read line incap convey emot</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>real snooz</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>like trap insid huge video game excit inan ima...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10657</th>\n",
              "      <td>stori could expand work compel singl featur cu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10658</th>\n",
              "      <td>limp along squirm induc fish water formula goe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10659</th>\n",
              "      <td>though excess tiresom uncertainti principl ver...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10660</th>\n",
              "      <td>chicago huge imagin success cast great credit ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10661</th>\n",
              "      <td>humor aspect jason x far entertain expect ever...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10662 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Review  Sentiment\n",
              "0      outer space buff might love film other find pl...          0\n",
              "1      serri want blend polit drama admir ambit bad h...          0\n",
              "2           kid often appear read line incap convey emot          0\n",
              "3                                             real snooz          0\n",
              "4      like trap insid huge video game excit inan ima...          0\n",
              "...                                                  ...        ...\n",
              "10657  stori could expand work compel singl featur cu...          0\n",
              "10658  limp along squirm induc fish water formula goe...          0\n",
              "10659  though excess tiresom uncertainti principl ver...          0\n",
              "10660  chicago huge imagin success cast great credit ...          1\n",
              "10661  humor aspect jason x far entertain expect ever...          0\n",
              "\n",
              "[10662 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMGK2ax0SGcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = (dane['Review'].values, dane['Sentiment'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02k463zOFMoT",
        "colab_type": "code",
        "outputId": "eba44d41-d90f-4ad2-cbad-7db5284e5c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "print(X,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['outer space buff might love film other find pleasur intermitt'\n",
            " 'serri want blend polit drama admir ambit bad help hand use stir ingredi also heavi one'\n",
            " 'kid often appear read line incap convey emot' ...\n",
            " 'though excess tiresom uncertainti principl verbal pretenti titl may hand redeem featur long discount abil bore'\n",
            " 'chicago huge imagin success cast great credit well one terrif score attitud spare'\n",
            " 'humor aspect jason x far entertain expect everyth els film tank'] [0 0 0 ... 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joHFqUjsSYy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tk = Tokenizer(lower = True)\n",
        "tk.fit_on_texts(X)\n",
        "X_seq = tk.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=100, padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weYw4FqEScKF",
        "colab_type": "code",
        "outputId": "a7a0ffac-2aca-45d6-cd7e-c038a46b0159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(dane['Review'][3],X_seq[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "real snooz [90, 5733]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL2poRylT4_u",
        "colab_type": "code",
        "outputId": "1a0ad347-cc20-4419-d3fb-de8a6f0ecbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(dane)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10662"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qczefK8W9Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_frac = 0.8\n",
        "train_x = X_pad[0:int(split_frac*len(dane))]\n",
        "train_y = y[0:int(split_frac*len(dane))]\n",
        "\n",
        "remaining_x = X_pad[int(split_frac*len(dane)):]\n",
        "remaining_y = y[int(split_frac*len(dane)):]\n",
        "\n",
        "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
        "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
        "\n",
        "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
        "test_y = remaining_y[int(len(remaining_y)*0.5):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS5622VEXGAP",
        "colab_type": "code",
        "outputId": "7227f44e-a40e-4fde-a5ec-0e663aaa73d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "print(len(train_x))\n",
        "print(len(train_y))\n",
        "print(len(valid_x))\n",
        "print(len(valid_y))\n",
        "print(len(test_x))\n",
        "print(len(test_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8529\n",
            "8529\n",
            "1066\n",
            "1066\n",
            "1067\n",
            "1067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1VzZ7PSQUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Ibta5aSb7O",
        "colab_type": "code",
        "outputId": "bf22738b-b7aa-49b8-b868-febdaec20e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 100])\n",
            "Sample input: \n",
            " tensor([[4100,  247,   81,  ...,    0,    0,    0],\n",
            "        [4940,  547, 3612,  ...,    0,    0,    0],\n",
            "        [ 194,   64, 9604,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 218,    9,  471,  ...,    0,    0,    0],\n",
            "        [ 908,   39,  325,  ...,    0,    0,    0],\n",
            "        [ 358,  309,    0,  ...,    0,    0,    0]], dtype=torch.int32)\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
            "        0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
            "        1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGOAvPbNYUqF",
        "colab_type": "code",
        "outputId": "a8502329-ef3f-4437-8fd4-9dc6f612ab7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from string import punctuation\n",
        "import collections\n",
        "print(punctuation)\n",
        "\n",
        "all_text = ''.join([c for c in dane if c not in punctuation])\n",
        "\n",
        "reviews_split = all_text.split('\\n')\n",
        "print ('Number of reviews :', len(reviews_split))\n",
        "\n",
        "all_text2 = ' '.join(reviews_split)\n",
        "# create a list of words\n",
        "words = all_text2.split()\n",
        "\n",
        "count_words=collections.Counter(words)\n",
        "\n",
        "total_words = len(words)\n",
        "sorted_words = count_words.most_common(total_words)\n",
        "\n",
        "vocab_to_int = {w:i for i, (w,c) in enumerate(sorted_words)}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "Number of reviews : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpynjF44yVUP",
        "colab_type": "text"
      },
      "source": [
        "# ***Modeeel***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx6DTm35wgTt",
        "colab_type": "code",
        "outputId": "6043bbc6-3b31-42f5-fc31-034b209e4440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)\n",
        "\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(layers.Embedding(input_dim=15000 , output_dim=128))\n",
        "\n",
        "model.add(layers.LSTM(128, dropout=0.2,recurrent_dropout=0.2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Dense(2, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(2, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, None, 128)         1920000   \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,051,713\n",
            "Trainable params: 2,051,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkAsCsdNxRyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DRJqbljWpTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbY5QnrO8FXR",
        "colab_type": "code",
        "outputId": "fe7db284-ca5c-4ae2-f87c-8f3fd468e406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "model.fit(train_x, train_y,\n",
        "          batch_size=32,\n",
        "          epochs=3,\n",
        "          validation_data=(valid_x, valid_y))\n",
        "score, acc = model.evaluate(test_x, test_y,\n",
        "                            batch_size=32)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8529 samples, validate on 1066 samples\n",
            "Epoch 1/3\n",
            "8529/8529 [==============================] - 87s 10ms/sample - loss: 0.6939 - accuracy: 0.4949 - val_loss: 0.6930 - val_accuracy: 0.5075\n",
            "Epoch 2/3\n",
            "8529/8529 [==============================] - 85s 10ms/sample - loss: 0.6935 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 3/3\n",
            "8529/8529 [==============================] - 85s 10ms/sample - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6933 - val_accuracy: 0.4925\n",
            "1067/1067 [==============================] - 1s 1ms/sample - loss: 0.6929 - accuracy: 0.5145\n",
            "Test score: 0.6929233240656687\n",
            "Test accuracy: 0.5145267\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}